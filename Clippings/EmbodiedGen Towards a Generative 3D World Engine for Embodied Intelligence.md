---
title: "EmbodiedGen: Towards a Generative 3D World Engine for Embodied Intelligence"
source: "https://arxiv.org/abs/2506.10600"
author:
  - "[[Wang Xinjie]]"
  - "[[Liu Liu]]"
  - "[[Cao Yu]]"
  - "[[Wu Ruiqi]]"
  - "[[Qin Wenkang]]"
  - "[[Wang Dehui]]"
  - "[[Sui Wei]]"
  - "[[Su Zhizhong]]"
published:
created: 2025-06-15
description: "Abstract page for arXiv paper 2506.10600: EmbodiedGen: Towards a Generative 3D World Engine for Embodied Intelligence"
tags:
  - "clippings"
---
\[Submitted on 12 Jun 2025\]

## Title:EmbodiedGen: Towards a Generative 3D World Engine for Embodied Intelligence

Authors:, , , , , , ,

[View PDF](https://arxiv.org/pdf/2506.10600) [HTML (experimental)](https://arxiv.org/html/2506.10600v1)

> Abstract:Constructing a physically realistic and accurately scaled simulated 3D world is crucial for the training and evaluation of embodied intelligence tasks. The diversity, realism, low cost accessibility and affordability of 3D data assets are critical for achieving generalization and scalability in embodied AI. However, most current embodied intelligence tasks still rely heavily on traditional 3D computer graphics assets manually created and annotated, which suffer from high production costs and limited realism. These limitations significantly hinder the scalability of data driven approaches. We present EmbodiedGen, a foundational platform for interactive 3D world generation. It enables the scalable generation of high-quality, controllable and photorealistic 3D assets with accurate physical properties and real-world scale in the Unified Robotics Description Format (URDF) at low cost. These assets can be directly imported into various physics simulation engines for fine-grained physical control, supporting downstream tasks in training and evaluation. EmbodiedGen is an easy-to-use, full-featured toolkit composed of six key modules: Image-to-3D, Text-to-3D, Texture Generation, Articulated Object Generation, Scene Generation and Layout Generation. EmbodiedGen generates diverse and interactive 3D worlds composed of generative 3D assets, leveraging generative AI to address the challenges of generalization and evaluation to the needs of embodied intelligence related research. Code is available at [this https URL](https://horizonrobotics.github.io/robot_lab/embodied_gen/index.html).

| Subjects: | Robotics (cs.RO); Computer Vision and Pattern Recognition (cs.CV) |
| --- | --- |
| Cite as: | [arXiv:2506.10600](https://arxiv.org/abs/2506.10600) \[cs.RO\] |
|  | (or [arXiv:2506.10600v1](https://arxiv.org/abs/2506.10600v1) \[cs.RO\] for this version) |
|  | [https://doi.org/10.48550/arXiv.2506.10600](https://doi.org/10.48550/arXiv.2506.10600)  arXiv-issued DOI via DataCite (pending registration) |

## Submission history

From: Xinjie Wang \[[view email](https://arxiv.org/show-email/a75c419d/2506.10600)\]  
**\[v1\]** Thu, 12 Jun 2025 11:43:50 UTC (17,907 KB)  

## Bibliographic and Citation Tools

Bibliographic Explorer *([What is the Explorer?](https://info.arxiv.org/labs/showcase.html#arxiv-bibliographic-explorer))*

Connected Papers *([What is Connected Papers?](https://www.connectedpapers.com/about))*

Litmaps *([What is Litmaps?](https://www.litmaps.co/))*

scite Smart Citations *([What are Smart Citations?](https://www.scite.ai/))*

## Code, Data and Media Associated with this Article

alphaXiv *([What is alphaXiv?](https://alphaxiv.org/))*

CatalyzeX Code Finder for Papers *([What is CatalyzeX?](https://www.catalyzex.com/))*

DagsHub *([What is DagsHub?](https://dagshub.com/))*

Gotit.pub *([What is GotitPub?](http://gotit.pub/faq))*

Hugging Face *([What is Huggingface?](https://huggingface.co/huggingface))*

Papers with Code *([What is Papers with Code?](https://paperswithcode.com/))*

ScienceCast *([What is ScienceCast?](https://sciencecast.org/welcome))*

## Demos

Replicate *([What is Replicate?](https://replicate.com/docs/arxiv/about))*

Hugging Face Spaces *([What is Spaces?](https://huggingface.co/docs/hub/spaces))*

TXYZ.AI *([What is TXYZ.AI?](https://txyz.ai/))*

## arXivLabs: experimental projects with community collaborators

arXivLabs is a framework that allows collaborators to develop and share new arXiv features directly on our website.

Both individuals and organizations that work with arXivLabs have embraced and accepted our values of openness, community, excellence, and user data privacy. arXiv is committed to these values and only works with partners that adhere to them.

Have an idea for a project that will add value for arXiv's community? [**Learn more about arXivLabs**](https://info.arxiv.org/labs/index.html).

[Which authors of this paper are endorsers?](https://arxiv.org/auth/show-endorsers/2506.10600) | [Disable MathJax](https://arxiv.org/abs/) ([What is MathJax?](https://info.arxiv.org/help/mathjax.html))