---
title: "MCPとAIエージェントが対決：あなたの設計は安全か？"
source: "https://zenn.dev/querypie/articles/95d6e4e7a29583"
author:
  - "[[Zenn]]"
published: 2025-05-20
created: 2025-05-20
description:
tags:
  - "clippings"
---
2

1

## 参考文献への謝辞

> **このホワイトペーパーは、Rakesh Gohel氏がLinkedInに投稿した「What people think AI agents are vs. What AI Agents actually are」のダイアグラムから深いインスピレーションを受けて作成されました。**
> 
> この可視化は、AIエージェントに対する認識のギャップと技術的構造の複雑さを直感的に示しており、本ホワイトペーパーの構造と問題意識の形成において重要な出発点となりました。参照した内容は付録に要約されています。Rakesh Gohel氏に、洞察とインスピレーションを提供いただいたことに、心より感謝申し上げます。
> 
> Rakesh Gohel氏のLinkedIn: [https://www.linkedin.com/in/rakeshgohel01/](https://www.linkedin.com/in/rakeshgohel01/)

![](https://storage.googleapis.com/zenn-user-upload/7b298595cf9c-20250520.png)

## 第1章： 役割と責任の違い

MCPサーバーとAIエージェントは、AI中心システムの核心的な構成要素です。この2つのコンポーネントは一つのフロー内で協力しますが、その目的と責任は本質的に異なります。しかし、実務ではこの2つの役割を混同するケースが頻繁に発生し、これはアーキテクチャ設計の誤り、権限の過剰付与、実行制御の失敗といった構造的なセキュリティ脆弱性につながる可能性があります［1］。このような混同は、単なる構造理解の誤りを超えて、実行権限の無秩序な拡張、ポリシーの迂回、ユーザー行動の監査不能領域の発生など、 **直接的なセキュリティリスク** を引き起こす可能性があります。

例えば、AIエージェントがユーザーのリクエストを解釈する機能を越えて、直接外部システムを呼び出すように設計されると、LLMの非決定性により予測不能な動作が発生したり、ポリシーに基づく制御なしに未承認のリソースへのアクセスが許可される可能性があります。逆に、MCPサーバーがユーザー意図の判断やポリシー決定まで担う場合、システムが意思決定を誤る構造的な不一致が生じ、責任が集中し、監査可能性（Auditability）と役割説明可能性（Explainability）が弱まります。

本章では、MCPサーバーとAIエージェントの役割を明確に区分し、誤解を防止するための責任範囲と機能限界を体系的に説明します。

#### MCPサーバーとは何ですか？

MCP（Model Context Protocol）サーバーは、AIエージェントが外部リソースにアクセスし、タスクを実行できるように接続するバックエンドインターフェース層です。多様なシステム（API、DB、SaaSなど）とAIエージェントの間を接続し、標準化された方法でリソースを抽象化して提供します［2］。MCPサーバーは単一の統合ゲートウェイのように動作し、AIエージェントが個々のシステムの実装詳細を知らなくてもタスクをリクエストできるように支援します。

しかし、MCPサーバーは単純なプロキシを超え、 **ポリシー評価、実行制御、セッション監査** などの機能は限定的にしかサポートされず、システム要件に応じて一部の機能は別層で補完することが一般的です［26］。

![](https://storage.googleapis.com/zenn-user-upload/53654fd3846f-20250520.png)

#### MCPサーバーの主要な責任構造

- **ツール接続とリソースルーティング（Tool Proxying）**  
	MCPは、多様な外部ツール（API、DB、ファイルなど）を標準化されたインターフェースで公開します。AIエージェントの要求を実際のシステム呼び出しに変換して転送するプロキシの役割を果たします。
- **ポリシー実行（Policy Enforcement）**  
	MCPは認証（Authentication）および基本的な権限付与（Authorization）を提供しますが、詳細なポリシーベースの条件評価（PBAC/ABACなど）はアーキテクチャ外部で補完する必要があります［3］。
- **コンテキストの保存と提供（Context Management）**  
	外部コンテキストストレージと連携し、ユーザーセッション、会話履歴、好みなどを管理でき、一貫したコンテキストの維持に貢献します。
- **タスクの調整とフロー制御 （Task Orchestration）**  
	抽象化されたエージェント要求を実際のシステム呼び出しに分解・組み合わせて、複数の呼び出しを処理できます。条件分岐やユーザー承認などの高度なフローは、別々の構成要素として分離されることもあります。
- **実行の安全性と監査保証 （Execution Control & Auditing）**  
	呼び出しログの記録、エラー処理、失敗対応などの機能はサポートされていますが、ポリシー違反の原因記録や承認履歴の監査などは選択的な実装要素です。

要約すると、MCPサーバーは実行接続とリソース抽象化に特化したプラットフォームであり、判断や制御を直接実行しません。必要に応じて、ポリシー実行や監査制御のためのセキュリティ層が組み込まれることがあります。

#### AIエージェントとは何ですか？

AIエージェントは、ユーザーと直接相互作用し、自然言語の命令を解釈し実行計画を策定する知能型インターフェース層です。主にLLM（Large Language Model）ベースの自然言語処理モデルを活用し、ユーザーのリクエストの文脈を理解し、必要なシステム呼び出しを決定します［4］。

#### AIエージェントの主要な機能

- **ユーザー意図の解釈:** エージェントは自然言語の質問や命令の意味を分析し、要求された目的を把握します。
- **計画の策定:** 目標を達成するための段階的な作業手順を構成します。
- **MCPインターフェースの呼び出し:** 外部のシステム連携が必要な場合、MCP APIを呼び出して該当するリソースに間接的にアクセスします［2］。
- **短期記憶と推論の管理:** 会話の流れやセッション中の一時的なコンテキストを維持し活用します。
- **応答生成:** ユーザーに結果を自然言語で伝達したり、次の作業を誘導します。

AIエージェントは、ユーザーの指示を解釈し計画を立てる脳の役割に集中し、実際の実行はMCPサーバーを通じて行われる必要があります。

![](https://storage.googleapis.com/zenn-user-upload/182ab3f638be-20250520.png)

---

#### 誤解を防止するための重要なポイントのまとめ

| 区分 | MCPサーバー | AIエージェント |
| --- | --- | --- |
| 役割 | 実行ルーティングおよびツール接続 | ユーザー入力の解釈と目的設定 |
| 主体性 | 受動実行者（実行のみを行う） | 能動計画者（決定のみを行う） |
| セキュリティ制御 | 制限的（ポリシーの執行は外部レイヤーで   拡張可能） | なし（ポリシー判断機能なし） |
| 必要な補完 | システム要件に応じてセキュリティレイヤー   （MCP PAMなど）で補完 | MCP ベースの実行委任を維持 |

#### 役割分担の概要

- **AIエージェントは「脳」の役割** として、ユーザーの目的を解釈し、計画を策定します。
- **MCPサーバーは「手足」の役割** として、定められた作業を安全に実行します［5］。
- この分担により、システムは **知能性** と **制御力** を同時に確保できます。

![](https://storage.googleapis.com/zenn-user-upload/3c1d15cbd935-20250520.png)

以下の図は、MCPサーバーとAIエージェントの役割分担を示しています。

**図：AIエージェントとMCPサーバーの役割区分**

![](https://storage.googleapis.com/zenn-user-upload/a09775d1136b-20250520.png)

**説明:** ユーザーがリクエストを入力すると、AI エージェントはこれを解釈して計画を策定します。実行リクエストはMCPサーバー経由で送信され、実際の作業は外部システムとの通信を通じて実行されます。この構造は **責任分離、ポリシーベースのフロー、持続可能な拡張性** を実現します。

次の章では、MCPとAIエージェントが **どのように相互作用するか** 、および実際のインターフェースが **どのような方法で実装されるか** を具体的に検討します。

## 第2章： 使い方とインターフェース方式

この章では、MCPサーバーとAIエージェントが **どのように使用されるか** 、および **どのようなインターフェースを提供するか** を具体的に説明します。両コンポーネントは相互作用の対象と通信方式が根本的に異なるため、これらの違いを正確に理解することが適切なシステム統合の核心です［6］。

#### MCPサーバーの使い方

MCPサーバーは、一般ユーザーよりも **AIエージェントまたはシステム開発者** が使用するコンポーネントです。主な使用方法は以下の通りです。

- **APIベースの呼び出し構造：** MCPサーバーはREST APIまたはgRPCベースのインターフェースを提供し、AIエージェントはこれを通じて必要な作業（例： `/fetchData` ， `/invokeService` ）をリクエストします。リクエストは通常JSON形式で、認証トークンと共に送信されます［7］。
- **ポリシーベースのリクエスト処理：** MCPはリクエストを受信時、ポリシー（PBAC、ABACなど）に基づいてタスクの実行可否を判断します。これには内部ポリシーエンジン（CedarまたはOPAベース）を呼び出し、ユーザー、リソース、目的を評価します［8］。
- **ツール/データブローカーの役割：** 内部的には、MCPサーバーは企業内のシステム（API、DB、クラウドサービスなど）と接続されており、AIエージェントの代わりにこれらのシステムにリクエストを送信し、応答を受け取って返却します。
- **セッションおよびコンテキスト維持機能：** 一部の実装では、MCPがセッション識別子や会話コンテキストを管理し、一貫した状態ベースの応答を可能にします。

重要な点は、 **最終ユーザーがMCPサーバーと直接相互作用しない** ことです。すべてのリクエストはAIエージェントまたはシステムコンポーネントを介してプロキシ形式で送信され、MCPサーバーは実行およびセキュリティの観点からのバックエンドコンポーネントとして機能します。

#### AIエージェントの使用方法

AIエージェントは、ユーザーまたは外部システムが直接アクセスするコンポーネントであり、多様なインターフェース形態を備えています。

- **対話型インターフェース（チャット/音声）：** ユーザーは自然言語でリクエストを入力し、AIエージェントは入力内容を分析して応答します。この際、自然言語処理と推論ロジックはLLM（大規模言語モデル）または事前定義されたスキルセットを基盤としています［9］。
- **アプリ/ウェブ統合機能：** エージェントはアプリケーション内のボタン、ワークフロートリガー、コマンドウィンドウなどの形式で統合され、ユーザーはこれらを通じて間接的にエージェントを呼び出します。
- **API形式のサービス：** AIエージェントを単一のREST APIまたはWebhookベースのサービスとして展開する場合もあり、この場合、外部システムが直接リクエストを送信し、JSON形式などで応答を受け取ります。
- **ビジネスロジック連携：** エージェントはユーザーのリクエストを解釈した後、必要に応じてMCPサーバーを呼び出して外部システムを間接的に利用します。MCPサーバーからデータを受け取った後、その情報を基にレスポンスを構成したり、後続の作業を計画します［10］。

要するに、AIエージェントは **人とシステムを接続する知能型インターフェース層** であり、その下位実行はMCPサーバーが担当します。

#### インターフェース方式の構造的差異

MCPサーバーとAIエージェントは、以下の通り異なる方法でインターフェースを構成します。

![](https://storage.googleapis.com/zenn-user-upload/71d1693c9cc4-20250520.png)

このような構造的な違いは、設計者にとって重要な基準となります。例えば、セキュリティ設定はMCPを中心に実施し、ユーザーインターフェースの改善はAIエージェントを中心に実施する必要があります。

## 第3章： 全体システムアーキテクチャ内の位置と関係

AI中心のシステムがますます複雑化するにつれ、MCPサーバーとAIエージェントが全体アーキテクチャ内でどのように配置され統合されるかを理解することは重要です。特にIT担当者や意思決定者は、システム設計時に両コンポーネントの相互作用方法とセキュリティ境界（Trust Boundary）を正確に区別する必要があります［12］。

#### アーキテクチャ上のMCPサーバーの位置と役割

**MCPサーバーはバックエンドミドルウェア層に位置し、以下の主要な機能を果たします：**

- **ツールおよびデータ接続：** AIエージェントからのリクエストを受け付け、多様なAPI、DB、SaaSシステムに接続します。
- **ポリシーベースの実行：** 認証、権限付与、API呼び出しのポリシー制御は、外部セキュリティ層であるMCP Agent PAM（ **Privileged Access Management** ）を通じて補完されます。
- **実行リクエストのルーティングと記録：** リクエストの流れを制御し、基本ログを残します。

特に、 **ポリシー強化、高度な監査、ユーザー行動分析機能** は、MCPサーバー自体ではなく **MCP Agent PAM** を通じて拡張されます。この拡張層は以下の機能を提供します：

- **ACLベースのアクセス制御：** リソースごとの細分化されたポリシー適用
- **ポリシーベースのリクエストフィルタリング （PBAC）：** 条件に基づく許可/拒否の評価を実施
- **監査ログ記録とセッション追跡：** APIリクエストと応答の全プロセスを構造化されたログで記録し、未承認の試行や例外発生状況を追跡します［13］。
- **DLP（データ損失防止）：** 機密データを含むかどうかを検出し、出力値をマスキングまたはブロックします［14］。
- **UEBA（ユーザーとエンティティの行動分析）：** ユーザーまたはエージェントの異常な行動を検出します。マシンラーニングに基づいてリスクを評価します［15］。

これらの機能は、 **MCPサーバーのセキュリティ/制御機能を実質的に完成** させる役割を果たし、実行フローの安定性と規制対応力を同時に確保できます。

#### アーキテクチャ上のAIエージェントの位置と役割

**AIエージェントはアプリケーション層またはユーザーインターフェース層で動作します。ユーザーの要求を受信し、必要に応じてLLM API呼び出しを通じて自然言語処理を実行したり、MCPサーバーにAPI要求を送信します。**

- **ユーザー要求処理：** 自然言語、UIクリック、メッセージなど多様な入力を受信します。
- **実行計画の策定：** 要求に基づいて必要な作業を判断します。
- **分岐処理：**
	- 自己応答可能の場合 → LLM API呼び出し
	- 外部データが必要な場合 → MCPサーバー呼び出し

このように、AIエージェントは **知能的な判断とフロー制御の出発点** であり、実際の実行フローはMCPサーバーおよびAgent PAMを通じて管理されます。

#### 全体システム内の相互関係

**以下の構造は、一般的なMCPベースのAIシステムのアーキテクチャを要約したものです：**

![](https://storage.googleapis.com/zenn-user-upload/0692568eb937-20250520.png)

この流れにおいて、AIエージェントはユーザー中心の入力を知能的に解釈し、MCPサーバーはこれを適切なバックエンドリソースに接続し、MCP Agent PAMはすべての実行パスに対して **ポリシー検証、行動監視、データ保護** を実施します。

この階層的な分離は、単なる技術的な構成の問題を超え、AIシステム設計時に **意図の解釈、実行制御、行動監査** の全プロセスを分離し、責任を持って設計できるように支援します。特に以下の実務上の利点を提供します：

- **ポリシー評価フローの明示的な区分：** AIエージェントはユーザーの意図を解釈し判断のみを行い、実際の実行に関する責任はMCPサーバーとAgent PAMが分離して担当します。
- **実行と応答の監査可能性の確保：** MCP Agent PAMは、リクエストと応答に関するすべてのイベントをポリシーの文脈と共に構造化して記録し、これは事後分析と事故対応の核心的な基盤となります。
- **データ保護とユーザー行動分析のリアルタイム連携：** DLPとUEBA機能は、単純なセキュリティ機能を超え、実行時の機密情報へのアクセス制御と異常パターンの検出を通じて、実行フロー自体を保護します。
- **技術的説明可能性（eXplainability）の基盤提供：** エージェントの判断経路と実行結果が分離されているため、各ステップを追跡・検証可能であり、規制対応だけでなく内部監査においても重要な基盤となります［27］。
- **役割ベースのセキュリティアーキテクチャの実現：** このような設計により、システムは拡張性だけでなく、責任分離（Separation of Duties）とZero Trust実行層を満たし、安全なAI運用環境を実現できます［16］［17］［18］。

## 第4章：主な誤解の事例と明確な説明

MCPサーバーとAIエージェントの構造と責任がどれだけ明確に設計されていても、実務では **誤解や混同の事例** が頻繁に発生します。この章では、代表的な3つの誤解を中心に、実際の事例を交えて説明し、それらをどのように区別し防止できるかを示します［19］。

#### 誤解1： 「MCPサーバーをAIエージェントのように使えないのでしょうか？」

**誤った理解**  
MCPサーバーに直接自然言語の命令を送ったり、AIのように賢く回答を返すことを期待する場合です。特にチャットボットなしでMCP APIに自然言語のリクエストを送る試みがよく見られます［20］。

**問題点**  
MCPサーバーは自然言語の解釈や目的の把握機能は一切持たず、 **定型化されたコマンドと認証された呼び出しのみに反応** します。このような使用は構造的にエラーを引き起こし、セキュリティおよび実行ポリシーが完全に迂回される可能性があります。

**正しい視点**  
ユーザーは常に **AIエージェントインターフェースを通じてMCPサーバーに間接的にアクセス** する必要があります。AIエージェントが自然言語を解釈し、それに応じてMCPサーバーに明確なAPI呼び出しを生成する必要があります［21］。

![](https://storage.googleapis.com/zenn-user-upload/ca647bb068c5-20250520.jpg)

#### 誤解2： 「AIエージェントがセキュリティも自動的に処理してくれるだろう？」

**誤った理解**

AIエージェントが非常に高度な知能で動作するため、データベースへの直接アクセスを許可したり、実行ポリシーを自動的に判断させても問題ないという考えです。

**問題点**

AIエージェントはAIモデルの特性上、予測不能な出力を生成する可能性があり、Prompt Injectionなどの **非構造化攻撃** に非常に脆弱です［22］。また、AIが自らセキュリティルールを一貫して適用するのは困難であり、中央管理が不可能になります。

**正しい視点**

AIエージェントは常に **MCPサーバー経由で制限された作業のみ実行** し、実際の権限判断、ポリシー適用、ログ記録は **MCP Agent PAM** で実施する必要があります。これにより、実行に対する制御権と責任が分離されます［23］。

#### 誤解3： 「どちらか一つだけでもシステムにならないでしょうか？」

**誤った理解**

MCPサーバーまたはAIエージェントのどちらか一つだけでシステムを構成できると判断しています。例えば、AIエージェントが直接DB/APIを呼び出したり、MCPに簡単なAI機能を追加してユーザークエリを処理するようにする提案です。

**問題点**

一つのコンポーネントにすべての役割を付与すると、 **責任分離が崩れ、柔軟性と保守性が急激に低下** します。特にセキュリティポリシー、エラー復旧、チーム間の協業において深刻な問題を引き起こす可能性があります［24］［25］。

**正しい視点**

2つのコンポーネントは **役割が明確に分離され** 、統合されたインターフェースを通じて連携を維持しつつ、独立して進化する能力を備えていなければなりません。AIエージェントはユーザーの文脈を把握し目的を確立し、MCPサーバーはその目的に従って実行可能なタスクを実行します［25］。ただし、セキュリティに関連するアクセス制御、ログ記録、DLP、UEBAは別オプションであり、主にMCP Agent PAMでその役割を果たします。

![](https://storage.googleapis.com/zenn-user-upload/2a1c112f0e27-20250520.jpg)

#### 要点まとめ

| 誤解 | 問題点の要約 | 修正戦略の要約 |
| --- | --- | --- |
| MCPサーバーをAIのように使用 | 自然言語の解釈不可、実行失敗 | AIエージェント → MCPサーバーの構造を維持 |
| AIエージェントがセキュリティまで担当 | ポリシーの迂回リスク、   予測不能な出力 | 統合セキュリティ層はMCP Agent PAMで独立して適用 |
| どちらか一方のみ使用可能 | 責任の過負荷、統合失敗、セキュリティ制御の不備 | 役割分離に基づく設計、APIベースの構造で相互接続を維持 |

## 第5章： 結論とまとめ

本ホワイトペーパーでは、MCPサーバーとAIエージェントの役割と責任を明確に区分し、その構造的な分離を通じて安全で拡張可能なAIシステムを設計する方法を提案しました。実務現場では、両コンポーネントを混同したり統合しようとする試みが多く見られますが、これにより生じるセキュリティ脆弱性、ポリシー制御の失敗、実行責任の曖昧化は、長期的にシステム運用リスクを増加させます。

#### 要約： 構造的分離がもたらす効果

- **AIエージェントは解釈と計画に集中すべきです。** ユーザーの目的を理解し、実行可能なタスクに分解する役割は、インテリジェントインターフェース層で実行されるべきです。
- **MCPサーバーは実行と接続に集中すべきです。** 外部リソースへの安全な呼び出し、リクエストのルーティング、ポリシーの適用の中核は、MCPサーバーに分離されるべきです。
- **MCP Agent PAMは実行の制御と監視層に拡張されるべきです。** AIエージェントが解釈したリクエストが実行される前に、そのリクエストがポリシーに準拠しているか、機密情報が含まれているか、ユーザーが異常な行動を示しているかなどをリアルタイムで分析・制御できる必要があります［11］［19］。

---

#### 実務設計時の考慮事項

1\. **インターフェースを分離し、フローを定義する必要があります。** エージェントとMCPはAPI呼び出しレベルで分離され、LLM APIとMCP APIは明確に分離されている必要があります。

2\. **すべての実行リクエストはMCP経由で処理される必要があります。** データベースアクセス、外部SaaS呼び出し、システム変更などのリクエストはMCPサーバー経由で中央管理され、直接実行はブロックされる必要があります。

3\. **MCP Agent PAMはセキュリティ制御において選択ではなく必須です。** 特に以下の領域で強力な機能が求められます：

- ポリシーベースの条件評価 （PBAC、ABAC、RBAC、ReBAC）
- ユーザー行動分析に基づく実行制御 （UEBA）
- 機密情報漏洩防止 （DLP）
- 実行フローに対する全面的な監査ログ記録 （Logging/Audit）

MCP Agent PAMのような実行制御層なしで、AIエージェントが直接システムAPIを呼び出すように設計されると、以下のセキュリティリスクが発生する可能性があります：

- 予測不能なLLM出力が即座に実行され、ポリシー回避や権限の濫用が発生
- 実行フローが監査されないため、ログの欠落や事故対応が不可能
- 機密情報の漏洩や異常行動の検出失敗により、内部侵害事故の発生確率が増加

したがって、PAM層はセキュリティ機能の拡張ではなく、実行フローの安全性と監視可能性を制度化する核心インフラとして位置付ける必要があります。

4\. **すべての層は説明可能でなければなりません。** リクエスト → ポリシー評価 → 実行 → 応答 → 監査ログまでのフローが構造化されており、これは規制対応だけでなくシステム運用透明性確保のための核心基盤です ［20］。

#### 結論

**AIエージェントがますます高度化し、LLM APIがより多くの自律性を獲得するにつれ、システムは以下の構造を備える必要があります：**

- **「誰が何を実行したか」** をシステム的に判断できること、
- **「どのような条件下でそれが許可されたか」** に関するポリシーに基づく説明が可能であること、
- **「その実行が正しいフローに従ったか」** をログとセッションベースの監査で検証できること。

これを可能にする構造が、 **MCPサーバーとAIエージェントの分離** 、および **MCP Agent PAMの統合拡張** です。AI中心のシステムを設計する際には、単なる連携レベルの統合ではなく、 **責任と制御に基づくアーキテクチャ構成** が最も重要です。

## 付録. AI エージェント：人々のイメージ vs. 実際の構成要素

AI エージェントは、これまで単純なチャットボットや自動化ツールと誤解されてきました。特に実務者は、Cursor、ChatGPT、AutoGPT などのシステムに触れる中でこれらを「エージェント」と認識していますが、これらのシステムはAI エージェントの機能の一部を実装した単一のツールレベルのインターフェースに過ぎません。つまり、自律性、行動の連続性、記憶構造、意思決定システムなどを包含していません。

以下は、人々が一般的に想像するAIエージェントのイメージと実際の構成要素との間の構造的な違いを視覚的に説明したものです：

![](https://storage.googleapis.com/zenn-user-upload/4fb8746233d0-20250520.png)

例えば、ChatGPTはGPTベースのテキスト生成エンジンであり、プロンプトに応答して言語結果を返すことはできますが、自ら目標を定義したり、外部システムと統合された行動を実行したりはしません。CursorはGPTを活用したコード編集ツールで、与えられた範囲内の作業を連続的に自動化することはできますが、創造的な目標設定や計画機能は組み込まれていません。一方、AutoGPTは計画-実行ループを構成する実験的なフレームワークとして注目されましたが、実際には固定されたループと制限されたメモリ構造の中で繰り返し呼び出しを行うのみで、複雑な状況では同じ判断を繰り返したり論理矛盾を引き起こす限界を示しました［4］。

このような誤解は、すぐに設計上の誤りや実行段階の失敗につながり得ます。例えば、単に「エージェントを導入する」とだけ考えてGPT APIを呼び出すレベルから始める場合、ポリシー評価、実行監査、役割分離、責任追跡性などのセキュリティ/運用要件を満たすことができません。したがって、実際のAIエージェント導入を検討する際には、以下の構成要素を必ず検討する必要があります：

- 目的に基づく計画の策定
- 外部システム連携のための標準化されたインターフェース（MCP）
- 実行フロー内のツール選択と判断構造
- 実行後の状態保持が可能な記憶構造
- 必要に応じて他のエージェントとの協業（A2A）

これらの機能を単一システムに統合できる場合に、初めて完成形のAIエージェントと呼ぶことができます。

AIエージェントは、単純なチャットボットとは異なり、ユーザーとの相互作用を超える複合的な機能を果たす必要があります。以下は、完全なAIエージェントが必ず備えるべき6つの核心的な構成要素です。

**1\. 言語モデルベースの脳**

AIエージェントの核心には、GPT-4のような超大規模言語モデル（LLM）が存在します。これは自然言語を理解し、応答を生成し、ユーザー指示に基づいて推論や要約を行う機能を備えています。しかし、言語モデルだけでは実行やツールの使用、長期記憶、意思決定など、エージェントの核心的な行動を完了できません。したがって、これは「脳」に過ぎず、残りの機能は別構造で補完する必要があります。

**2\. 短期/長期記憶（エピソード記憶を含む）**

人間が過去の経験を記憶するように、AIエージェントにも記憶システムが必要です。

- 短期記憶：現在の会話/作業の文脈を維持
- 長期記憶（エピソード記憶）：過去の作業の失敗/成功、ユーザーフィードバックなどを保存し再利用

実際にはベクトルDBを活用し、類似度検索に基づいて過去のイベントを呼び出し、これによりユーザー体験の一貫性とエージェントの漸進的な学習を可能にします。

**3\. 計画策定および意思決定エンジン**

エージェントが単に命令を実行するだけでなく、自ら何をすべきかを判断するためには、必ず計画エンジン（Planner）が必要です。

例えば「競合他社のマーケティング戦略調査」という命令が与えられた場合：

① 関連ウェブサイトの調査  
② SNSトレンド分析  
③ データ要約  
④ 報告書作成

このような段階的な実行を自動的に設計し、分岐させられることが真のエージェントと言えます。この構造はAutoGPTで試行されましたが、複雑な意思決定には依然として制限があります［4］。

**4\. 外部のツール統合 （Tool Integration）**

現実の問題はGPTだけでは解決できません。エージェントは以下のツール連携能力が必要です：

- リアルタイム情報検索： Google、Bing API
- 計算： 計算機またはPython実行環境
- データ処理： SQLデータベース、文書要約ツール、スプレッドシートインターフェースなど

エージェントは状況に応じてツールを選択し実行し、その結果を次のステップに反映できる必要があります。これは単純なチャットボットにはない能力であり、運用環境に展開可能な「実行型エージェント」を実現するための必須機能です。

**5\. A2A 協業 （Agent-to-Agent）**

一つのエージェントがすべてのタスクを実行するよりも、役割が分かれた複数のエージェントが相互に協業する方式が効率的です。

例：

- 企画エージェント → ドラフト作成
- 分析エージェント → 文法修正および評価
- 報告エージェント → プロンプトの生成および提出

A2A方式は、エラー補正、創造性向上、安定性確保などに効果的であり、最近ではLangGraph、CrewAIなどのフレームワークがこれをサポートしています［9］［16］。

**6\. MCP（Model Context Protocol）**

AIエージェントが新しいツールやシステムに柔軟に接続するためには、標準化された接続構造が必要です。MCPは、AIエージェントが実行時に以下のことを可能にします：

- 利用可能なリソースの自動探索
- 標準化されたフォーマットでのAPI呼び出し
- 行動可能性の推論によるポリシー適用

例えば、あるシステムがMCPインターフェースを提供する場合、エージェントはコードの修正なしでそのシステムと相互作用できます。これは大規模なAI環境における柔軟性と再利用性を最大化する基盤となります［2］。

**実践例：マーケティングリサーチエージェント  
「競合他社Aの最近のマーケティング戦略を調査し、要約してください。」**

このタスクを実行するエージェントは、以下の手順で動作します：

1. 目標解釈： 具体的な目標の定義 – ニュース収集、トレンド分析、公式資料の確認
2. 計画策定： ウェブ検索 → コンテンツ収集 → 要約 → 報告書作成
3. ツール活用： Google Search API、Twitter API など
4. 記憶活用： 類似リサーチ結果の呼び出しと報告書構成の最適化
5. 結果生成： 概要レポートの作成とフィードバックに基づく修正
6. 実行制御と協業： 文書編集エージェントとの協業、MCPベースのツールの動的接続

**結論  
人々はしばしばChatGPTやCursorのような単一のツールを「AIエージェント」と誤解します。しかし、真のAIエージェントは、以下の複合アーキテクチャを備えた実行ベースのシステムです：**

| 構成要素 | 一般ツール | AIエージェント |
| --- | --- | --- |
| 自然言語処理エンジン | はい | はい |
| メモリ機能 | 限定的/なし | 必須 |
| 計画および判断構造 | なし | 必須 |
| 外部ツール統合 | なし | 必須 |
| 他のエージェントとの協業 | なし | 選択的だが重要 |
| 実行コンテキスト標準化（MCP） | なし | 高度な機能だが重要 |

外観だけを見て機能を誤解するのではなく、内部アーキテクチャを明確に理解し、それに基づいた実行制御、メモリ管理、ツール連携戦略が整備されていなければ、実際に動作可能なエージェントを構築することはできません。

## 参考文献

\[1\] IBM, “Build Trust in AI,” IBM Trustworthy AI Guide, 2023. \[Online\]. Available:\[2\] K. Park, “Securing AI-Driven Workflows with Model Context Protocol,” QueryPie White Paper, 2025.\[Online\]. Available:\[3\] Amazon Web Services, “Cedar Policy Language: Developer Guide,” AWS Documentation, 2024.\[Online\]. Available:\[4\] I. Belcic, “What is AutoGPT?,” IBM Think Blog, Apr. 2024.\[Online\]. Available:\[5\] National Institute of Standards and Technology (NIST), “SP 800-207: Zero Trust Architecture,” Final Publication, Aug. 2020.\[Online\]. Available:\[6\] D. R. Thomas, “Software architecture as a tool for organizational alignment,” IEEE Software, vol. 29, no. 2, pp. 58–60, Mar./Apr. 2012. doi: 10.1109/MS.2012.42  
\[7\] G. Smith, L. Zhou, and R. Patel, “Designing secure REST APIs,” in Proc. 11th IEEE Int. Conf. Web Services (ICWS), San Francisco, CA, USA, Jun. 2018, pp. 431–439. doi: 10.1109/ICWS.2018.00061  
\[8\] T. Hinrichs and B. Bichakjian, “OPA: Policy-based control for cloud-native infrastructure,” Open Policy Agent Documentation, 2023.\[Online\]. Available:\[9\] H. Chase and L. C. G. Rogers, “LangChain: A framework for developing applications with large language models,” arXiv preprint arXiv:2305.14322, May 2023.\[Online\]. Available:\[10\] M. R. Anderson and S. Suri, “Orchestration of hybrid agents in cloud-native platforms,” ACM Computing Surveys, vol. 55, no. 4, pp. 1–32, 2023. doi: 10.1145/3507347  
\[11\] J. Lee and M. Kim, “Human-in-the-loop integration for secure LLM applications,” IEEE Access, vol. 11, pp. 56102–56116, 2023. doi: 10.1109/ACCESS.2023.3278412  
\[12\] C. Rich and A. B. Winston, “Trust boundaries in intelligent systems,” AI Magazine, vol. 33, no. 2, pp. 49–59, Summer 2022. doi: 10.1609/aimag.v33i2.2457  
\[13\] Y. Chen and A. C. Arpaci-Dusseau, “Unifying secure proxy gateways in microservice architectures,” in Proc. IEEE Int. Conf. Cloud Engineering (IC2E), San Francisco, CA, USA, Apr. 2022, pp. 115–124. doi: 10.1109/IC2E53581.2022.00023  
\[14\] Google Cloud, “VPC Service Controls Overview,” Google Cloud Documentation, 2023.\[Online\]. Available:\[15\] M. Allix et al., “Cybersecurity of Large Language Models: A Survey,” in IEEE Access, vol. 11, pp. 116944–116971, 2023. \[Online\]. Available: [https://ieeexplore.ieee.org/document/10293079](https://ieeexplore.ieee.org/document/10293079)  
\[16\] L. Zeng, “Agent-as-a-Gateway pattern in distributed AI systems,” in Proc. 30th Pattern Languages of Programs Conf. (PLoP), Oct. 2023.\[Online\]. Available: [https://hillside.net/plop/2023/papers/](https://hillside.net/plop/2023/papers/)  
\[17\] B. Ferguson, “Designing trust boundaries in enterprise architectures,” SANS Institute Whitepaper, 2022.\[Online\]. Available: [https://www.sans.org/white-papers/40170](https://www.sans.org/white-papers/40170)  
\[18\] A. Kumar, “Zero Trust in AI service invocation,” Cybersecurity Engineering, vol. 7, no. 1, pp. 41–50, Jan. 2024.  
\[19\] J. Lee and D. Han, “Common misconceptions in AI and access control,” in Proc. AI Security Conf., Seoul, Korea, Sept. 2023.  
\[20\] K. Bae, Y. Hong, and S. Kwon, “Limitations of direct natural language interfaces to execution frameworks,” IEEE Internet Computing, vol. 27, no. 1, pp. 68–76, Jan./Feb. 2023. doi: 10.1109/MIC.2023.3244567  
\[21\] SuperbCrew, “Convergence Introduces Proxy 1.0: The AI Assistant That Navigates Websites Like a Human and Gets Work Done,” SuperbCrew, Sep. 2023. \[Online\]. Available:\[22\] OWASP Foundation, “OWASP Top 10 for Large Language Model Applications,” OWASP, 2023.\[Online\]. Available:\[23\] L. Ding and B. Guo, “Agent architecture with execution firewalls,” IEEE Transactions on Dependable and Secure Computing, vol. 19, no. 5, pp. 1984–1995, Sept./Oct. 2022. doi: 10.1109/TDSC.2022.3149214  
\[24\] A. Patil, H. Nam, and R. Shah, “Design anti-patterns in agent-platform integration,” International Journal of Software Engineering and Knowledge Engineering, vol. 31, no. 3, pp. 211–226, 2022. doi: 10.1142/S0218194022500113  
\[25\] K. Park, “Google Agentspace vs. QueryPie MCP PAM: Why Security Still Matters,” QueryPie White Paper, 2025.\[Online\]. Available:\[26\] K. Park, “AI Autonomous Access Control: When Agents Make Decisions,” QueryPie White Paper, 2025.\[Online\]. Available:\[27\] K. Park, “Next Step: Real-Time Execution Control with MCP PAM,” QueryPie White Paper, 2025.\[Online\]. Available:\[28\] K. Park, “Redefining PAM for the MCP Era,” QueryPie White Paper, 2025.\[Online\]. Available:

2

1

2

1